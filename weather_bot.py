# This program will record weather forecast data for a entered location. 

print("Welcome to our WeatherBot. This python bot will retrive a weather forecast for a desired locations.")
print("All you must do is enter the location you wish to get a weather report for")
print("Then, just specify weather you want to save the report to a file and output, or simply just output the report")

# Import libraries to web scrape weather data
import bs4
import requests
from urllib.request import urlopen as uReq
from bs4 import BeautifulSoup as soup

USER_AGENT = "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36"
# US english
LANGUAGE = "en-US,en;q=0.5"

outputHeader = "Access Time, City, State, Temperature, Weather, Precip (%), Humidity (%), Wind Speed (mph)"

def openUrequest(url):
    ''' Creates a new requests Session. Takes in a url as an argument in the form of string. 
        Returns a BeautifulSoup object containing HTML code. Headers are set/required in order to 
        "trick" google that we are a browser, so as not to have it block our request
    '''
    session = requests.Session()
    session.headers['User-Agent'] = USER_AGENT
    session.headers['Accept-Language'] = LANGUAGE
    session.headers['Content-Language'] = LANGUAGE
    html = session.get(url)
    # create a new soup
    soup = bs4.BeautifulSoup(html.text, "html.parser")
    return soup

def writeDataToFile(soup):
    ''' This function will open our output file in "append" mode, and write to it the weather
        report generated by our program onto a single line. Closes file on completion
    '''
    file = open("WeatherData.csv", "a")
    dataArr = pullDataFromHTML(soup)
    file.write(dataArr)
    file.close()


def pullDataFromHTML(soup):
    ''' Creates a datastring containing all of the fields we have gathered on the given location.
        Takes in a BeautifulSoup object as a parameter, and returns the datastring.
    '''
    dataString = '\n'
    dataString += getCurTime(soup) + ", "
    dataString += getLocation(soup) + ", "
    dataString += getTemp(soup) + " deg F, "
    dataString += getWeather(soup) + ", "
    dataString += getPrecip(soup) + ", "
    dataString += getHumid(soup) + ", "
    dataString += getWind(soup)
    return dataString

def buildURL(queryParams):
    ''' Constructs URL given entered parameters. Returns the URL as a string.
        This is the web page from which we will attempt to pull data
    '''
    base_url = 'https://www.google.com/search?q=weather'
    my_url = base_url
    for param in queryParams:
        my_url += "+" + param.replace(" ", "+")
    return my_url

def getCurTime(page_soup):
    ''' Pulls the current time of the request from the soup and returns it '''
    return (page_soup.find("div", attrs={"id": "wob_dts"}).text)

def getLocation(page_soup):
    ''' Pulls the location from the page souup and returns it '''
    return (page_soup.find("div", attrs={"id": "wob_loc"}).text)

def getTemp(page_soup):
    ''' Pulls the current temperature for the given location and returns it '''
    return (page_soup.find("span", attrs={"id": "wob_tm"}).text)

def getWeather(page_soup):
    ''' Pulls the current weather for the given location and returns it '''
    return (page_soup.find("span", attrs={"id": "wob_dc"}).text)

def getPrecip(page_soup):
    ''' Pull the current precipitation chance (%) and returns it '''
    return (page_soup.find("span", attrs={"id": "wob_pp"}).text)

def getHumid(page_soup):
    ''' Pull the current humidity percentage and returns it '''
    return (page_soup.find("span", attrs={"id": "wob_hm"}).text)

def getWind(page_soup):
    ''' Pull the current wind speed and returns it as a string '''
    return (page_soup.find("span", attrs={"id": "wob_ws"}).text)

# User Input Validation via try catch 
while True:
    try:
        # Have user enter the City and State separated by commas
        reqForecast = input("Please enter the city and state in CSV Format: ")
        # Have the user answer whether or not they want the report written to a file
        storeLocation = input("Would you like to store this location and report? (Y/N): ")
        
        # Verify fields
        queryParams = reqForecast.split(",")
        if(queryParams[1]):
            if storeLocation == "Y" or storeLocation == "y":
                writeToFile = True
            else:
                writeToFile = False
                
        break
        
    except IndexError:
        print("Oops! That was no valid location. Try again...")


# Construct URL to perform webscraping from given user input

           
notDone = True

while notDone:
    try:
        # create a copy of the webpage in question
        my_url = buildURL(queryParams)
        soup = openUrequest(my_url)
        print(outputHeader)
        print(pullDataFromHTML((soup)))
        if writeToFile:
            writeDataToFile(soup)
 
        again = input("Search for another location? (Y/N): ")
        if again == "Y":
            queryParams = input("Please enter the city and state in CSV Format: ").split(",")
            writeToFile = input("Would you like to store this location and report (Y/N): ")
            if writeToFile == "Y" or writeToFile == "y":
                writeToFile = True
            else:
                writeToFile = False
        else:
            break
    except IOError:
        print("Aborting, forecast for entered location not found. Please re-run program and try again.")
        break
        